{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colin's Pipeline Experiments\n",
    "### Objectives:\n",
    "- Create a SingleImagePipeline so we can run fast-iteration experiments on just a single image\n",
    "- Create a CentraPipeline that calls SingleImagePipeline\n",
    "- Modularize the soccer_net_pipeline and migrate all operations to SingleImagePipeline\n",
    "- Run all systematic ops from CentralPipeline (more than one tracklet)\n",
    "\n",
    "### Main benefit from creating a `BatchImagePipeline` and a `CentralPipeline`\n",
    "Decoupling large-scale systematic training versus testing. The main pipeline trains the model, creates output processed images and does so by systematically traversing all the tracklets. I want to be able to see what pre-processing is happening to the image so I can understand what is being fed to the model. I also just want to be able to pass a single raw image to the model so I can get fast results. Right now everything is coupled together by all the tracklets, and I don't want to traverse all of them or even a single tracklet, but maybe only a single image from a single tracklet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Run Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install yacs\n",
    "#%pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\n",
      "Current working directory:  c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\ModelDevelopment\\experiments\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent.parent))\n",
    "print(str(Path.cwd().parent.parent))\n",
    "print(\"Current working directory: \", os.getcwd())\n",
    "\n",
    "from ModelDevelopment.CentralPipeline import CentralPipeline\n",
    "from ModelDevelopment.ImageBatchPipeline import ImageBatchPipeline\n",
    "from DataProcessing.DataPreProcessing import DataPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-05 10:16:57] - [INFO]: DataPreProcessing initialized. Universe of available data paths:\n",
      "[2025-03-05 10:16:57] - [INFO]: ROOT_DATA_DIR: c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\extracted\n",
      "[2025-03-05 10:16:57] - [INFO]: TEST_DATA_DIR: c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\extracted\\test\\images\n",
      "[2025-03-05 10:16:57] - [INFO]: TRAIN_DATA_DIR: c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\extracted\\train\\images\n",
      "[2025-03-05 10:16:57] - [INFO]: CHALLENGE_DATA_DIR: c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\extracted\\challenge\\images\n",
      "[2025-03-05 10:16:57] - [INFO]: PRE_TRAINED_MODELS_DIR: c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\data\\pre_trained_models\n",
      "[2025-03-05 10:16:57] - [INFO]: REID_PRE_TRAINED: c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\data\\pre_trained_models\\reid\n",
      "[2025-03-05 10:16:57] - [INFO]: REID_MODEL_1: c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\data\\pre_trained_models\\reid\\dukemtmcreid_resnet50_256_128_epoch_120.ckpt\n",
      "[2025-03-05 10:16:57] - [INFO]: REID_MODEL_2: c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\data\\pre_trained_models\\reid\\market1501_resnet50_256_128_epoch_120.ckpt\n",
      "[2025-03-05 10:16:57] - [INFO]: REID_CONFIG_YAML: c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\data\\pre_trained_models\\reid\\configs\\256_resnet50.yml\n",
      "[2025-03-05 10:16:57] - [INFO]: PROCESSED_DATA_OUTPUT_DIR: c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\n",
      "[2025-03-05 10:16:57] - [INFO]: PROCESSED_DATA_OUTPUT_DIR_TRAIN: c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\\train\n",
      "[2025-03-05 10:16:57] - [INFO]: PROCESSED_DATA_OUTPUT_DIR_TEST: c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\\test\n",
      "[2025-03-05 10:16:57] - [INFO]: PROCESSED_DATA_OUTPUT_DIR_CHALLENGE: c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\\challenge\n",
      "[2025-03-05 10:16:57] - [INFO]: Using device: cuda\n",
      "[2025-03-05 10:16:57] - [INFO]: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "[2025-03-05 10:16:57] - [INFO]: Min tracklet: 0\n",
      "[2025-03-05 10:16:57] - [INFO]: Max tracklet: 1426\n"
     ]
    }
   ],
   "source": [
    "pipeline = CentralPipeline(\n",
    "  input_data_path=DataPaths.TRAIN_DATA_DIR.value,\n",
    "  output_processed_data_path=DataPaths.PROCESSED_DATA_OUTPUT_DIR_TRAIN.value,\n",
    "  single_image_pipeline=False,\n",
    "  display_transformed_image_sample=True,\n",
    "  num_image_samples=1,\n",
    "  use_cache=False\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-05 10:16:57] - [INFO]: Running the SoccerNet pipeline.\n",
      "[2025-03-05 10:16:57] - [INFO]: Using single-process GPU mode to generate features.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f2d633681c4caa8722932472b192e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading tracklets (GPU):   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-05 10:16:59] - [INFO]: Removed cached tracklet feature file (use_cache: False): c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\\train\\0_features.npy\n",
      "c:\\Users\\colin\\miniconda3\\envs\\UBC\\Lib\\site-packages\\pytorch_lightning\\utilities\\migration\\migration.py:208: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.1.4 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint c:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\data\\pre_trained_models\\reid\\dukemtmcreid_resnet50_256_128_epoch_120.ckpt`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-05 10:17:01] - [INFO]: Saved features for tracklet with shape (1, 2048)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DataPreProcessing.pass_through_gaussian_outliers_filter() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_soccernet_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m  \u001b[49m\u001b[43mnum_tracklets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m  \u001b[49m\u001b[43mnum_images_per_tracklet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\ModelDevelopment\\CentralPipeline.py:109\u001b[0m, in \u001b[0;36mCentralPipeline.run_soccernet_pipeline\u001b[1;34m(self, num_tracklets, num_images_per_tracklet)\u001b[0m\n\u001b[0;32m    106\u001b[0m         pipeline\u001b[38;5;241m.\u001b[39mrun_model_chain()\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# Process the entire batch of images for the tracklet\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mImageBatchPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_processed_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracklet_data_file_stub\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModelUniverse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDUMMY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilence_logs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mdisplay_transformed_image_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_transformed_image_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     pipeline\u001b[38;5;241m.\u001b[39mrun_model_chain()\n",
      "File \u001b[1;32mc:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\ModelDevelopment\\ImageBatchPipeline.py:29\u001b[0m, in \u001b[0;36mImageBatchPipeline.__init__\u001b[1;34m(self, raw_image_tensor, output_file, model, silence_logs, display_transformed_image_sample)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger \u001b[38;5;241m=\u001b[39m CustomLogger()\u001b[38;5;241m.\u001b[39mget_logger()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Preprocess the image(s) via the transform pipeline.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# The method image_transform_pipeline expects a raw image tensor and returns features.\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessed_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_preprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_transform_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_image_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# NOTE: This is not the image after it was passed through the image transform pipeline because we cannot visualize that.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplay_transformed_image_sample:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# For display, we assume raw_image_tensor is a single image (or take first if batch).\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\colin\\OneDrive\\Desktop\\UBC\\Jersey-Number-Recognition\\DataProcessing\\DataPreProcessing.py:163\u001b[0m, in \u001b[0;36mDataPreProcessing.image_transform_pipeline\u001b[1;34m(self, raw_image_batch, output_feature_data_file, model_version)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;124;03mProcess a single raw image through the centroid model pipeline.\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m  np.ndarray: The flattened feature vector for the input image.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpass_through_reid_centroid(raw_image_batch, output_feature_data_file, model_version)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpass_through_gaussian_outliers_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_image_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_feature_data_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m processed_image\n",
      "\u001b[1;31mTypeError\u001b[0m: DataPreProcessing.pass_through_gaussian_outliers_filter() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "pipeline.run_soccernet_pipeline(\n",
    "  num_tracklets=1,\n",
    "  num_images_per_tracklet=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UBC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
