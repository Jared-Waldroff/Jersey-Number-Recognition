{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Run Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# # Path to the problematic checkpoint\n",
    "# checkpoint_path = r\"c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\pre_trained_models\\reid\\dukemtmcreid_resnet50_256_128_epoch_120.ckpt\"\n",
    "\n",
    "# # Allow loading of ModelCheckpoint objects (since PyTorch 2.6 blocks this by default)\n",
    "# torch.serialization.add_safe_globals([ModelCheckpoint])\n",
    "\n",
    "# # Load the checkpoint safely\n",
    "# checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "# # Print out keys to inspect conflicting ones\n",
    "# print(\"Checkpoint keys:\", checkpoint.keys())\n",
    "\n",
    "# # Remove ModelCheckpoint states (if they exist)\n",
    "# keys_to_remove = [key for key in checkpoint.keys() if \"ModelCheckpoint\" in key]\n",
    "# for key in keys_to_remove:\n",
    "#     del checkpoint[key]\n",
    "\n",
    "# # Save the cleaned checkpoint\n",
    "# fixed_checkpoint_path = checkpoint_path.replace(\".ckpt\", \"_fixed.ckpt\")\n",
    "# torch.save(checkpoint, fixed_checkpoint_path)\n",
    "\n",
    "# print(f\"Fixed checkpoint saved to: {fixed_checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\n",
      "Current working directory:  c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\ModelDevelopment\\experiments\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent.parent))\n",
    "print(str(Path.cwd().parent.parent))\n",
    "print(\"Current working directory: \", os.getcwd())\n",
    "\n",
    "from ModelDevelopment.CentralPipeline import CentralPipeline\n",
    "from ModelDevelopment.ImageBatchPipeline import ImageBatchPipeline\n",
    "from DataProcessing.DataPreProcessing import DataPaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreaded Studies Research Findings\n",
    "- ThreadPoolExecutor works best for CentralPipeline pre-processing step (i.e. everything before run_pose)\n",
    "- Time taken to process one batch of 32 tracklets: 251 seconds => (251*32)/3600 = 2.35 hours ETA @ 200 images per batch cap, num_threads = 6x3 = 18\n",
    "- Note on the GPU_SEMAPHORE constant inside ImageFeatureTransformPipeline: this is always capped at 1 so we only offload 1 batch of images to the GPU\n",
    "- Since this gate is capped at 1, we can control the amount of data offloaded to the GPU via the image_batch_size param to CentralPipeline and only that\n",
    "- Since caching is implemented, you can try setting the gate to 2 for even faster results, and if the process crashes, keep restarting with use_cache=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-23 16:47:25 [INFO] DataPreProcessing initialized. Universe of available data paths:\n",
      "2025-03-23 16:47:25 [INFO] ROOT_DATA_DIR: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\extracted\n",
      "2025-03-23 16:47:25 [INFO] TEST_DATA_GT: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\extracted\\test\\test_gt.json\n",
      "2025-03-23 16:47:25 [INFO] TRAIN_DATA_GT: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\extracted\\train\\train_gt.json\n",
      "2025-03-23 16:47:25 [INFO] TEST_DATA_DIR: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\extracted\\test\\images\n",
      "2025-03-23 16:47:25 [INFO] TRAIN_DATA_DIR: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\extracted\\train\\images\n",
      "2025-03-23 16:47:25 [INFO] CHALLENGE_DATA_DIR: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\extracted\\challenge\\images\n",
      "2025-03-23 16:47:25 [INFO] PRE_TRAINED_MODELS_DIR: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\pre_trained_models\n",
      "2025-03-23 16:47:25 [INFO] REID_PRE_TRAINED: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\pre_trained_models\\reid\n",
      "2025-03-23 16:47:25 [INFO] STR_PRE_TRAINED: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\pre_trained_models\\str\n",
      "2025-03-23 16:47:25 [INFO] STR_MODEL: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\pre_trained_models\\str\\parseq_epoch=24-step=2575-val_accuracy=95.6044-val_NED=96.3255.ckpt\n",
      "2025-03-23 16:47:25 [INFO] REID_MODEL_1: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\pre_trained_models\\reid\\dukemtmcreid_resnet50_256_128_epoch_120.ckpt\n",
      "2025-03-23 16:47:25 [INFO] REID_MODEL_2: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\pre_trained_models\\reid\\market1501_resnet50_256_128_epoch_120.ckpt\n",
      "2025-03-23 16:47:25 [INFO] REID_CONFIG_YAML: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\pre_trained_models\\reid\\configs\\256_resnet50.yml\n",
      "2025-03-23 16:47:25 [INFO] RESNET_MODEL: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\pre_trained_models\\resnet\\legibility_resnet34_soccer_20240215.pth\n",
      "2025-03-23 16:47:25 [INFO] PROCESSED_DATA_OUTPUT_DIR: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\n",
      "2025-03-23 16:47:25 [INFO] PROCESSED_DATA_OUTPUT_DIR_TRAIN: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\\train\n",
      "2025-03-23 16:47:25 [INFO] PROCESSED_DATA_OUTPUT_DIR_TEST: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\\test\n",
      "2025-03-23 16:47:25 [INFO] PROCESSED_DATA_OUTPUT_DIR_CHALLENGE: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\\challenge\n",
      "2025-03-23 16:47:25 [INFO] COMMON_PROCESSED_OUTPUT_DATA_TRAIN: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\\train\\common_data\n",
      "2025-03-23 16:47:25 [INFO] COMMON_PROCESSED_OUTPUT_DATA_TEST: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\\test\\common_data\n",
      "2025-03-23 16:47:25 [INFO] COMMON_PROCESSED_OUTPUT_DATA_CHALLENGE: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\\challenge\\common_data\n",
      "2025-03-23 16:47:25 [INFO] STREAMLINED_PIPELINE: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\StreamlinedPipelineScripts\n",
      "2025-03-23 16:47:25 [INFO] ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "2025-03-23 16:47:25 [INFO] Min tracklet: 0\n",
      "2025-03-23 16:47:25 [INFO] Max tracklet: 1210\n",
      "2025-03-23 16:47:25 [INFO] Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# TODO: Add tracklets_override to pass a list of tracklets to process; tracklets_override=[\"8\", \"9\", \"10\"]\n",
    "# NOTE: It is recommended you delete the entire processed_data/{challenge/test/train} before running this to 100% avoid issues with old data.\n",
    "# Furthermore, you should always restart your kernel before every new run because sometimes there are problems with paths\n",
    "pipeline = CentralPipeline(\n",
    "  tracklets_to_process_override=[\"1\"],\n",
    "  #num_tracklets=1210,\n",
    "  num_images_per_tracklet=10,\n",
    "  input_data_path=DataPaths.TEST_DATA_DIR.value,\n",
    "  output_processed_data_path=DataPaths.PROCESSED_DATA_OUTPUT_DIR_TEST.value,\n",
    "  common_processed_data_dir=DataPaths.COMMON_PROCESSED_OUTPUT_DATA_TEST.value,\n",
    "  gt_data_path=DataPaths.TEST_DATA_GT.value,\n",
    "  single_image_pipeline=False,\n",
    "  display_transformed_image_sample=False, # NOTE: DO NOT USE. Code is parallelized so we cannot show images anymore. Code breaks, but first one will show if True.\n",
    "  num_image_samples=1,\n",
    "  use_cache=True, # Set to false if you encounter data inconsistencies.\n",
    "  suppress_logging=False,\n",
    "  \n",
    "  # --- PARALLELIZATION PARAMS --- These settings are optimal for an NVIDIA RTX 3070 Ti Laptop GPU.\n",
    "  num_workers=3,            # CRITICAL optimisation param. Adjust accordingly.\n",
    "  tracklet_batch_size=32,   # CRITICAL optimisation param. Adjust accordingly. \n",
    "  image_batch_size=50,      # CRITICAL optimisation param. Adjust accordingly. \n",
    "  num_threads_multiplier=2  # CRITICAL optimisation param. Adjust accordingly. Interpretation: num_threads = num_workers * num_threads_multiplier\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose speed up timing\n",
    "BENCHMARK\n",
    "- end-to-end for 1 tracklet, 10 images: 1 minute\n",
    "- just for pose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-23 16:47:25 [INFO] Running the SoccerNet pipeline.\n",
      "2025-03-23 16:47:25 [INFO] Tracklet override applied. Using provided tracklets: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e729856abb421595d805ecc2df535b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-23 16:47:25 [INFO] Tracklet batch size: 32\n",
      "2025-03-23 16:47:25 [INFO] Image batch size: 50\n",
      "2025-03-23 16:47:25 [INFO] Number of workers: 3\n",
      "2025-03-23 16:47:25 [INFO] Number of threads created: 6\n",
      "2025-03-23 16:47:25 [INFO] Skipping preprocessing for tracklet: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\\test\\1\n",
      "2025-03-23 16:47:25 [INFO] All tracklets in 0-1 are cached. Skipping feature generation.\n",
      "2025-03-23 16:47:25 [INFO] Generating json for pose\n",
      "2025-03-23 16:47:25 [INFO] Reading legible & illegible results from cache (both global files exist).\n",
      "2025-03-23 16:47:25 [INFO] Done generating json for pose\n",
      "2025-03-23 16:47:25 [INFO] Detecting pose\n",
      "2025-03-23 16:47:41 [INFO] Current working directory:  c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\pose\\ViTPose\n",
      "apex is not installed\n",
      "apex is not installed\n",
      "apex is not installed\n",
      "Current working directory:  c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\n",
      "False \n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "pose/ViTPose/configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/ViTPose_huge_coco_256x192.py\n",
      "pose/ViTPose/checkpoints/vitpose-h.pth\n",
      "load checkpoint from local path: pose/ViTPose/checkpoints/vitpose-h.pth\n",
      "Using cached results from: c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\\test\\common_data\\pose_results.json\n",
      "Total images: 9, Already processed: 9, Remaining: 0\n",
      "Saved combined results to c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\\test\\common_data\\pose_results.json\n",
      "\n",
      "\n",
      "2025-03-23 16:47:41 [ERROR] C:\\Users\\colin\\miniconda3\\envs\\vitpose\\lib\\site-packages\\mmcv\\runner\\checkpoint.py:302: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, map_location=map_location)\n",
      "\n",
      "\n",
      "2025-03-23 16:47:41 [INFO] Done detecting pose\n"
     ]
    }
   ],
   "source": [
    "pipeline.run_soccernet(\n",
    "  run_soccer_ball_filter=False,\n",
    "  generate_features=False,\n",
    "  run_filter=False,\n",
    "  run_legible=False,\n",
    "  run_legible_eval=False,\n",
    "  run_pose=True,\n",
    "  run_crops=False,\n",
    "  run_str=False,\n",
    "  run_combine=False,\n",
    "  run_eval=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UBC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
