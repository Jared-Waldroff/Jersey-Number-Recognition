{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent.parent))\n",
    "print(str(Path.cwd().parent.parent))\n",
    "print(\"Current working directory: \", os.getcwd())\n",
    "\n",
    "from ModelDevelopment.CentralPipeline import CentralPipeline\n",
    "from ModelDevelopment.ImageBatchPipeline import ImageBatchPipeline\n",
    "from DataProcessing.DataPreProcessing import DataPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_test = DataPaths.CHALLENGE_DATA_GT.value\n",
    "# #Schema of gt_test: {\"0\": 4, \"1\": 93, \"2\": 25, \"3\": -1, \"4\": -1,\n",
    "\n",
    "# # load the json and compile a list of all tracklets with -1 as not_legible and all other tracklets as legible\n",
    "# with open(gt_test, 'r') as f:\n",
    "#     data = json.load(f)\n",
    "#     legible = []\n",
    "#     illegible = []\n",
    "    \n",
    "#     for key, value in data.items():\n",
    "#         if value == -1:\n",
    "#             illegible.append(key)\n",
    "#         else:\n",
    "#             legible.append(key)\n",
    "    \n",
    "# print(\"Legible tracklets: \", legible)\n",
    "# print(\"Illegible tracklets: \", illegible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete soccer_ball.json files\n",
    "# import os\n",
    "# root_path = r\"C:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\extracted\\test\\images\"\n",
    "\n",
    "# for tracklet in range(1, 1210):\n",
    "#   path = os.path.join(root_path, str(tracklet))\n",
    "  \n",
    "#   # If there is a .soccer_ball.json file in there, delete it\n",
    "#   if os.path.exists(os.path.join(path, \"soccer_ball.json\")):\n",
    "#     os.remove(os.path.join(path, \"soccer_ball.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = CentralPipeline(\n",
    "  #tracklets_to_process_override=[109, 88, 34, 151, 19, 68, 67, 128, 57, 178, 189, 196, 214, 242, 258, 271, 304, 327, 320, 352, 375, 378, 414, 416, 439, 425, 451, 453, 454, 466, 499, 511, 513, 526, 528, 567, 576, 594, 619, 623, 646, 687, 682, 709, 711, 717, 739, 758, 767, 795, 788, 840, 843, 832, 841, 852, 847, 851, 856, 850, 868, 866, 871, 901, 902, 904, 900, 907, 928, 939, 944, 961, 984, 983, 1005, 1039, 1064, 1063, 1077, 1091, 1101, 1137, 1152, 1153, 1160, 1167, 1157, 1165, 1206],\n",
    "  #tracklets_to_process_override=[327, 711, 907, 1064], # These ones are now passing\n",
    "  #tracklets_to_process_override=[327]\n",
    "  #tracklets_to_process_override=[327],\n",
    "  #tracklets_to_process_override=illegible,\n",
    "  #tracklets_to_process_override=[168, 167, 162, 97, 39, 87, 89, 134, 61, 172, 164, 199, 215, 260, 267, 269, 281, 276, 288, 295, 317, 325, 340, 345, 374, 394, 388, 386, 391, 406, 408, 434, 437, 459, 471, 514, 532, 558, 683, 748, 770, 790, 802, 827, 861, 869, 879, 897, 895, 909, 964, 981, 999, 1023, 1031, 1025, 1033, 1030, 1055, 1088, 1087, 1169, 1175, 1174, 1173, 1183, 1170, 1179, 1184, 1185],\n",
    "  num_tracklets=1210,\n",
    "  #num_images_per_tracklet=50,\n",
    "  input_data_path=DataPaths.TEST_DATA_DIR.value,\n",
    "  output_processed_data_path=DataPaths.PROCESSED_DATA_OUTPUT_DIR_TEST.value,\n",
    "  common_processed_data_dir=DataPaths.COMMON_PROCESSED_OUTPUT_DATA_TEST.value,\n",
    "  gt_data_path=DataPaths.TEST_DATA_GT.value,\n",
    "  display_transformed_image_sample=False, # NOTE: DO NOT USE. Code is parallelized so we cannot show images anymore. Code breaks, but first one will show if True.\n",
    "  use_cache=True, # Set to false to rebuild the cache\n",
    "  suppress_logging=False,\n",
    "  use_image_enhancement=True,\n",
    "  \n",
    "  # --- PARALLELIZATION PARAMS --- These settings are optimal for an NVIDIA RTX 3070 Ti Laptop GPU.\n",
    "  num_workers=2,            # CRITICAL optimisation param. Adjust accordingly. Pre-processing: 4 | STR: 2 | Crops: 4\n",
    "  tracklet_batch_size=32,   # CRITICAL optimisation param. Adjust accordingly. Always 32\n",
    "  image_batch_size=300,     # CRITICAL optimisation param. Adjust accordingly. Pre-processing: 200 | STR: 100 | Crops: 200\n",
    "  num_threads_multiplier=6  # CRITICAL optimisation param. Adjust accordingly. Pre-processing: 4\n",
    "  )                         #                              Interpretation: num_threads = num_workers * num_threads_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.run_soccernet(\n",
    "  run_soccer_ball_filter=False,\n",
    "  generate_features=True,\n",
    "  run_filter=True,\n",
    "  run_legible=True,\n",
    "  run_legible_eval=True,\n",
    "  run_pose=True,\n",
    "  run_crops=True,\n",
    "  run_str=True,\n",
    "  run_combine=True,\n",
    "  run_eval=True,\n",
    "  use_clip4str=True,\n",
    "  pyscript=False,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark (current pipeline metrics)\n",
    "### Results\n",
    "- 2025-03-29 14:44:05 [INFO] Correct 1051 out of 1210. Accuracy 86.85950413223141%.\n",
    "- 2025-03-29 14:44:05 [INFO] TP=766, TN=285, FP=70, FN=89\n",
    "- 2025-03-29 14:44:05 [INFO] Precision=0.916267942583732, Recall=0.895906432748538\n",
    "- 2025-03-29 14:44:05 [INFO] F1=0.9059727971614429\n",
    "- 2025-03-29 14:44:05 [INFO] Saved failed legibility cases to:  c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\\test\\common_data\\failed_legibility_cases.json\n",
    "\n",
    "### Analysis\n",
    "legible_but_marked_illegible: 89 cases\n",
    "109, 88, 34, 151, 19, 68, 67, 128, 57, 178, 189, 196, 214, 242, 258, 271, 304, 327, 320, 352, 375, 378, 414, 416, 439, 425, 451, 453, 454, 466, 499, 511, 513, 526, 528, 567, 576, 594, 619, 623, 646, 687, 682, 709, 711, 717, 739, 758, 767, 795, 788, 840, 843, 832, 841, 852, 847, 851, 856, 850, 868, 866, 871, 901, 902, 904, 900, 907, 928, 939, 944, 961, 984, 983, 1005, 1039, 1064, 1063, 1077, 1091, 1101, 1137, 1152, 1153, 1160, 1167, 1157, 1165, 1206\n",
    "\n",
    "illegible_but_marked_legible: 70 cases\n",
    "168, 167, 162, 97, 39, 87, 89, 134, 61, 172, 164, 199, 215, 260, 267, 269, 281, 276, 288, 295, 317, 325, 340, 345, 374, 394, 388, 386, 391, 406, 408, 434, 437, 459, 471, 514, 532, 558, 683, 748, 770, 790, 802, 827, 861, 869, 879, 897, 895, 909, 964, 981, 999, 1023, 1031, 1025, 1033, 1030, 1055, 1088, 1087, 1169, 1175, 1174, 1173, 1183, 1170, 1179, 1184, 1185\n",
    "\n",
    "- Total misclassifications: 159\n",
    "- False negatives (legible marked as illegible): 89\n",
    "- False positives (illegible marked as legible): 70\n",
    "- Percentage of false negatives: 7.36%\n",
    "- Percentage of false positives: 5.79%\n",
    "- Combined percentage of errors as a percentage of total cases: 13.14%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "failed_cases = f\"{DataPaths.COMMON_PROCESSED_OUTPUT_DATA_CHALLENGE.value}/failed_legibility_cases.json\"\n",
    "\n",
    "# Load this JSON file\n",
    "with open(failed_cases, 'r') as f:\n",
    "    failed_cases_dict = json.load(f)\n",
    "    # Print the every key and its associated value (value will be a list so need to make that printable with \",\".join):\n",
    "    for key, value in failed_cases_dict.items():\n",
    "        print(f\"{key}: {len(value)} cases\")\n",
    "        if len(value) > 0:\n",
    "            print(f\"{', '.join(value)}\")\n",
    "        print()\n",
    "    \n",
    "    # Summary statistics\n",
    "    legible_but_marked_illegible = len(failed_cases_dict.get(\"legible_but_marked_illegible\", []))\n",
    "    illegible_but_marked_legible = len(failed_cases_dict.get(\"illegible_but_marked_legible\", []))\n",
    "    total_errors = legible_but_marked_illegible + illegible_but_marked_legible\n",
    "    \n",
    "    print(f\"Total misclassifications: {total_errors}\")\n",
    "    print(f\"False negatives (legible marked as illegible): {legible_but_marked_illegible}\")\n",
    "    print(f\"False positives (illegible marked as legible): {illegible_but_marked_legible}\")\n",
    "    print(f\"Percentage of false negatives: {legible_but_marked_illegible / 1210 * 100:.2f}%\")\n",
    "    print(f\"Percentage of false positives: {illegible_but_marked_legible / 1210 * 100:.2f}%\")\n",
    "    print(f\"Combined percentage of errors as a percentage of total cases: {total_errors / 1210 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "# import torch\n",
    "# from torch import nn\n",
    "\n",
    "# model = timm.create_model(\"timm/vit_base_patch16_224.orig_in21k_ft_in1k\", pretrained=False)\n",
    "# model.head = nn.Linear(model.head.in_features, 10)\n",
    "# model.load_state_dict(\n",
    "#     torch.hub.load_state_dict_from_url(\n",
    "#         \"https://huggingface.co/edadaltocg/vit_base_patch16_224_in21k_ft_svhn/resolve/main/pytorch_model.bin\",\n",
    "#         map_location=\"cpu\",\n",
    "#         file_name=\"vit_base_patch16_224_in21k_ft_svhn.pth\",\n",
    "#     )\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UBC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
