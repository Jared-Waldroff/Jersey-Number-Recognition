{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent.parent))\n",
    "print(str(Path.cwd().parent.parent))\n",
    "print(\"Current working directory: \", os.getcwd())\n",
    "\n",
    "from ModelDevelopment.CentralPipeline import CentralPipeline\n",
    "from ModelDevelopment.ImageBatchPipeline import ImageBatchPipeline\n",
    "from DataProcessing.DataPreProcessing import DataPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracklets_to_process_override_batch1 = [i for i in range(0, 711)] # COLIN\n",
    "tracklets_to_process_override_batch2 = [i for i in range(712, 1426)] # JARED Second half of the tracklets (605 items)\n",
    "#merge_cache = [i for i in range(0, 1426)]\n",
    "\n",
    "pipeline = CentralPipeline(\n",
    "  num_tracklets=1211,\n",
    "  #num_images_per_tracklet=50,\n",
    "  #tracklets_to_process_override=tracklets_to_process_override_batch1,\n",
    "  input_data_path=DataPaths.TEST_DATA_DIR.value,\n",
    "  output_processed_data_path=DataPaths.PROCESSED_DATA_OUTPUT_DIR_TEST.value,\n",
    "  common_processed_data_dir=DataPaths.COMMON_PROCESSED_OUTPUT_DATA_TEST.value,\n",
    "  gt_data_path=DataPaths.TEST_DATA_GT.value,\n",
    "  use_cache=True, # Set to false to rebuild the cache\n",
    "  suppress_logging=False,\n",
    "  use_image_enhancement=False,\n",
    "  \n",
    "  # --- PARALLELIZATION PARAMS --- These settings are optimal for an NVIDIA RTX 3070 Ti Laptop GPU.\n",
    "  num_workers=2,                   # CRITICAL optimisation param. Adjust accordingly. STR: 1 | Everything else: 2\n",
    "  tracklet_batch_size=32,          # CRITICAL optimisation param. Adjust accordingly. Always 32\n",
    "  image_batch_size=100,            # CRITICAL optimisation param. Adjust accordingly. STR: 50 | Everything else: 100-200\n",
    "  num_threads_multiplier=4         # CRITICAL optimisation param. Adjust accordingly.\n",
    "  )                                # -> Interpretation: num_threads = num_workers * num_threads_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.aggregate_legibility_results_data()\n",
    "#pipeline.aggregate_pose()\n",
    "#pipeline.aggregate_str_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.run_soccernet(\n",
    "  run_soccer_ball_filter=False,\n",
    "  generate_features=True,\n",
    "  run_filter=False,\n",
    "  run_legible=True,\n",
    "  run_legible_eval=True,\n",
    "  run_pose=True,\n",
    "  run_crops=True,\n",
    "  run_str=True,\n",
    "  run_combine=False,\n",
    "  run_eval=False,\n",
    "  use_clip4str=True,\n",
    "  pyscript=False,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark (current pipeline metrics)\n",
    "### Results\n",
    "- 2025-03-29 14:44:05 [INFO] Correct 1051 out of 1210. Accuracy 86.85950413223141%.\n",
    "- 2025-03-29 14:44:05 [INFO] TP=766, TN=285, FP=70, FN=89\n",
    "- 2025-03-29 14:44:05 [INFO] Precision=0.916267942583732, Recall=0.895906432748538\n",
    "- 2025-03-29 14:44:05 [INFO] F1=0.9059727971614429\n",
    "- 2025-03-29 14:44:05 [INFO] Saved failed legibility cases to:  c:\\Users\\colin\\OneDrive\\Desktop\\Jersey-Number-Recognition\\data\\SoccerNet\\jersey-2023\\processed_data\\test\\common_data\\failed_legibility_cases.json\n",
    "\n",
    "### Analysis\n",
    "legible_but_marked_illegible: 89 cases\n",
    "109, 88, 34, 151, 19, 68, 67, 128, 57, 178, 189, 196, 214, 242, 258, 271, 304, 327, 320, 352, 375, 378, 414, 416, 439, 425, 451, 453, 454, 466, 499, 511, 513, 526, 528, 567, 576, 594, 619, 623, 646, 687, 682, 709, 711, 717, 739, 758, 767, 795, 788, 840, 843, 832, 841, 852, 847, 851, 856, 850, 868, 866, 871, 901, 902, 904, 900, 907, 928, 939, 944, 961, 984, 983, 1005, 1039, 1064, 1063, 1077, 1091, 1101, 1137, 1152, 1153, 1160, 1167, 1157, 1165, 1206\n",
    "\n",
    "illegible_but_marked_legible: 70 cases\n",
    "168, 167, 162, 97, 39, 87, 89, 134, 61, 172, 164, 199, 215, 260, 267, 269, 281, 276, 288, 295, 317, 325, 340, 345, 374, 394, 388, 386, 391, 406, 408, 434, 437, 459, 471, 514, 532, 558, 683, 748, 770, 790, 802, 827, 861, 869, 879, 897, 895, 909, 964, 981, 999, 1023, 1031, 1025, 1033, 1030, 1055, 1088, 1087, 1169, 1175, 1174, 1173, 1183, 1170, 1179, 1184, 1185\n",
    "\n",
    "- Total misclassifications: 159\n",
    "- False negatives (legible marked as illegible): 89\n",
    "- False positives (illegible marked as legible): 70\n",
    "- Percentage of false negatives: 7.36%\n",
    "- Percentage of false positives: 5.79%\n",
    "- Combined percentage of errors as a percentage of total cases: 13.14%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# failed_cases = f\"{DataPaths.COMMON_PROCESSED_OUTPUT_DATA_CHALLENGE.value}/failed_legibility_cases.json\"\n",
    "\n",
    "# # Load this JSON file\n",
    "# with open(failed_cases, 'r') as f:\n",
    "#     failed_cases_dict = json.load(f)\n",
    "#     # Print the every key and its associated value (value will be a list so need to make that printable with \",\".join):\n",
    "#     for key, value in failed_cases_dict.items():\n",
    "#         print(f\"{key}: {len(value)} cases\")\n",
    "#         if len(value) > 0:\n",
    "#             print(f\"{', '.join(value)}\")\n",
    "#         print()\n",
    "    \n",
    "#     # Summary statistics\n",
    "#     legible_but_marked_illegible = len(failed_cases_dict.get(\"legible_but_marked_illegible\", []))\n",
    "#     illegible_but_marked_legible = len(failed_cases_dict.get(\"illegible_but_marked_legible\", []))\n",
    "#     total_errors = legible_but_marked_illegible + illegible_but_marked_legible\n",
    "    \n",
    "#     print(f\"Total misclassifications: {total_errors}\")\n",
    "#     print(f\"False negatives (legible marked as illegible): {legible_but_marked_illegible}\")\n",
    "#     print(f\"False positives (illegible marked as legible): {illegible_but_marked_legible}\")\n",
    "#     print(f\"Percentage of false negatives: {legible_but_marked_illegible / 1210 * 100:.2f}%\")\n",
    "#     print(f\"Percentage of false positives: {illegible_but_marked_legible / 1210 * 100:.2f}%\")\n",
    "#     print(f\"Combined percentage of errors as a percentage of total cases: {total_errors / 1210 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "# import torch\n",
    "# from torch import nn\n",
    "\n",
    "# model = timm.create_model(\"timm/vit_base_patch16_224.orig_in21k_ft_in1k\", pretrained=False)\n",
    "# model.head = nn.Linear(model.head.in_features, 10)\n",
    "# model.load_state_dict(\n",
    "#     torch.hub.load_state_dict_from_url(\n",
    "#         \"https://huggingface.co/edadaltocg/vit_base_patch16_224_in21k_ft_svhn/resolve/main/pytorch_model.bin\",\n",
    "#         map_location=\"cpu\",\n",
    "#         file_name=\"vit_base_patch16_224_in21k_ft_svhn.pth\",\n",
    "#     )\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UBC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
